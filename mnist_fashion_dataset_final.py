# -*- coding: utf-8 -*-
"""MNIST_Fashion_Dataset_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KF38wVrC3qIgXD5sC4y5WIeqSQbfFmB7

##Assignment No. 03

# Modern Deep Learning:
# Classify Fashion-MNIST with a simple CNN in Keras
"""

import tensorflow as tf

import numpy as np
import matplotlib.pyplot as plt


(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)

"""## Visualize the data"""

print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)


print(x_train.shape[0], 'train set')
print(x_test.shape[0], 'test set')


fashion_mnist_labels = ["T-shirt/top",
                        "Trouser",
                        "Pullover",
                        "Dress",
                        "Coat",
                        "Sandal",
                        "Shirt",
                        "Sneaker",
                        "Bag",
                        "Ankle boot"]


img_index = 5

label_index = y_train[img_index]

print ("y = " + str(label_index) + " " +(fashion_mnist_labels[label_index]))

plt.imshow(x_train[img_index])

w, h = 28, 28
x_train = x_train.reshape(x_train.shape[0], w, h, 1)
x_test = x_test.reshape(x_test.shape[0], w, h, 1)

x_train.shape

from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten

model = tf.keras.Sequential()

model.add(Conv2D(filters=64,
                 kernel_size=2,
                 padding='same',
                 activation='relu',
                 input_shape=(28,28,1)
                 ))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.3))

model.add(Conv2D(filters=32,
                 kernel_size=2,
                 padding='same',
                 activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.3))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.summary()

# Commented out IPython magic to ensure Python compatibility.
BATCH_SIZE=1000
EPOCHS = 20

model.compile(loss='sparse_categorical_crossentropy',
             optimizer='adam',
             metrics=['accuracy'])
# %time history = model.fit(x_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_split=0.2,verbose=1)

train_loss, train_accuracy = model.evaluate(x_train, y_train, batch_size=BATCH_SIZE)
train_accuracy

test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)
test_accuracy

y_hat = model.predict(x_test)

# Plot a single test image, its predicted label and ground truth
index = np.random.randint(0, x_test.shape[0])  # Choose a random index for the test image

plt.figure(figsize=(6, 6))
plt.imshow(np.squeeze(x_test[index]))
plt.title("Predicted: {}\nTrue: {}".format(fashion_mnist_labels[np.argmax(y_hat[index])],
                                           fashion_mnist_labels[y_test[index]]),
          color=("green" if np.argmax(y_hat[index]) == y_test[index] else "red"))
plt.axis('off')
plt.show()


# # Plot a random sample of 10 test images, their predicted labels and ground truth
# figure = plt.figure(figsize=(20, 8))
# for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):
#     ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])
#     # Display each image
#     ax.imshow(np.squeeze(x_test[index]))
#     predict_index = np.argmax(y_hat[index])
#     true_index = y_test[index]
#     # Set the title for each image
#     ax.set_title("{} ({})".format(fashion_mnist_labels[predict_index],
#                                   fashion_mnist_labels[true_index]),
#                                   color=("green" if predict_index == true_index else "red"))

